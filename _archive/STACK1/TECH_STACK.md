# TableRound æŠ€æœ¯æ ˆè¯¦ç»†è®²è§£

## ğŸ“‹ ç›®å½•

- [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
- [æ ¸å¿ƒæŠ€æœ¯æ¶æ„](#æ ¸å¿ƒæŠ€æœ¯æ¶æ„)
- [ç¼–ç¨‹è¯­è¨€ä¸æ¡†æ¶](#ç¼–ç¨‹è¯­è¨€ä¸æ¡†æ¶)
- [AIæ¨¡å‹é›†æˆ](#aiæ¨¡å‹é›†æˆ)
- [æ•°æ®å­˜å‚¨ä¸ç¼“å­˜](#æ•°æ®å­˜å‚¨ä¸ç¼“å­˜)
- [å›¾åƒå¤„ç†æŠ€æœ¯](#å›¾åƒå¤„ç†æŠ€æœ¯)
- [ç½‘ç»œé€šä¿¡](#ç½‘ç»œé€šä¿¡)
- [å¼€å‘å·¥å…·ä¸ç¯å¢ƒ](#å¼€å‘å·¥å…·ä¸ç¯å¢ƒ)
- [éƒ¨ç½²ä¸è¿ç»´](#éƒ¨ç½²ä¸è¿ç»´)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [å®‰å…¨è€ƒè™‘](#å®‰å…¨è€ƒè™‘)

---

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

TableRoundæ˜¯ä¸€ä¸ªåŸºäºPythonçš„å¤šæ™ºèƒ½ä½“äº¤äº’ç³»ç»Ÿï¼Œé‡‡ç”¨ç°ä»£åŒ–çš„å¼‚æ­¥ç¼–ç¨‹æ¶æ„ï¼Œé›†æˆå¤šç§AIæ¨¡å‹ï¼Œå®ç°æ™ºèƒ½ä½“é—´çš„å¤æ‚å¯¹è¯ã€å›¾åƒç†è§£ã€è®°å¿†ç®¡ç†å’Œåˆ›æ„ç”ŸæˆåŠŸèƒ½ã€‚

### æ ¸å¿ƒç‰¹æ€§
- **å¤šæ™ºèƒ½ä½“åä½œ**ï¼šæ”¯æŒ6ä¸ªä¸åŒè§’è‰²çš„æ™ºèƒ½ä½“åŒæ—¶å·¥ä½œ
- **ä¸¤é˜¶æ®µAIæ¨¡å‹**ï¼šè§†è§‰ç†è§£ + å¯¹è¯ç”Ÿæˆçš„æ··åˆæ¶æ„
- **å®æ—¶æµå¼è¾“å‡º**ï¼šæ”¯æŒæµå¼å¯¹è¯å’Œå®æ—¶åé¦ˆ
- **å…¨å±€è®°å¿†ç³»ç»Ÿ**ï¼šåŸºäºRedisçš„åˆ†å¸ƒå¼è®°å¿†ç®¡ç†
- **å›¾åƒæ™ºèƒ½å¤„ç†**ï¼šè‡ªåŠ¨å‹ç¼©ã€æ ¼å¼è½¬æ¢å’Œè§†è§‰ç†è§£
- **åˆ›æ„å†…å®¹ç”Ÿæˆ**ï¼šæ”¯æŒæ–‡æœ¬å’Œå›¾åƒçš„AIç”Ÿæˆ

---

## ğŸ—ï¸ æ ¸å¿ƒæŠ€æœ¯æ¶æ„

### ç³»ç»Ÿæ¶æ„æ¨¡å¼
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç”¨æˆ·ç•Œé¢å±‚     â”‚    â”‚   ä¸šåŠ¡é€»è¾‘å±‚     â”‚    â”‚   æ•°æ®å­˜å‚¨å±‚     â”‚
â”‚                â”‚    â”‚                â”‚    â”‚                â”‚
â”‚ â€¢ CLI Terminal â”‚    â”‚ â€¢ å¯¹è¯ç®¡ç†å™¨     â”‚    â”‚ â€¢ Redisç¼“å­˜     â”‚
â”‚ â€¢ æµå¼è¾“å‡º     â”‚â—„â”€â”€â–ºâ”‚ â€¢ æ™ºèƒ½ä½“ç®¡ç†     â”‚â—„â”€â”€â–ºâ”‚ â€¢ æ–‡ä»¶å­˜å‚¨     â”‚
â”‚ â€¢ ç”¨æˆ·äº¤äº’     â”‚    â”‚ â€¢ è®°å¿†ç³»ç»Ÿ      â”‚    â”‚ â€¢ æ—¥å¿—ç³»ç»Ÿ     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   AIæ¨¡å‹å±‚      â”‚
                    â”‚                â”‚
                    â”‚ â€¢ OpenRouter   â”‚
                    â”‚ â€¢ Google Geminiâ”‚
                    â”‚ â€¢ DeepSeek     â”‚
                    â”‚ â€¢ è±†åŒ…API      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è®¾è®¡æ¨¡å¼åº”ç”¨

1. **å·¥å‚æ¨¡å¼**ï¼šAIæ¨¡å‹çš„åŠ¨æ€åˆ›å»ºå’Œé…ç½®
2. **è§‚å¯Ÿè€…æ¨¡å¼**ï¼šæ™ºèƒ½ä½“é—´çš„æ¶ˆæ¯ä¼ é€’å’Œäº‹ä»¶é€šçŸ¥
3. **ç­–ç•¥æ¨¡å¼**ï¼šä¸åŒAIæä¾›å•†çš„æ¥å£é€‚é…
4. **å•ä¾‹æ¨¡å¼**ï¼šå…¨å±€é…ç½®å’Œæ—¥å¿—ç®¡ç†
5. **é€‚é…å™¨æ¨¡å¼**ï¼šç»Ÿä¸€ä¸åŒAIæ¨¡å‹çš„è°ƒç”¨æ¥å£

---

## ğŸ’» ç¼–ç¨‹è¯­è¨€ä¸æ¡†æ¶

### Python 3.8+ æ ¸å¿ƒæŠ€æœ¯æ ˆ

#### å¼‚æ­¥ç¼–ç¨‹æ¡†æ¶
```python
# æ ¸å¿ƒå¼‚æ­¥åº“
import asyncio          # å¼‚æ­¥ç¼–ç¨‹åŸºç¡€
import aiohttp          # å¼‚æ­¥HTTPå®¢æˆ·ç«¯
import aiofiles         # å¼‚æ­¥æ–‡ä»¶æ“ä½œ
```

**é€‰æ‹©ç†ç”±**ï¼š
- **é«˜å¹¶å‘å¤„ç†**ï¼šæ”¯æŒåŒæ—¶å¤„ç†å¤šä¸ªæ™ºèƒ½ä½“çš„å¹¶å‘è¯·æ±‚
- **éé˜»å¡I/O**ï¼šç½‘ç»œè¯·æ±‚å’Œæ–‡ä»¶æ“ä½œä¸ä¼šé˜»å¡ä¸»çº¿ç¨‹
- **èµ„æºæ•ˆç‡**ï¼šç›¸æ¯”å¤šçº¿ç¨‹ï¼Œåç¨‹æ¶ˆè€—æ›´å°‘çš„ç³»ç»Ÿèµ„æº

#### æ ¸å¿ƒä¾èµ–åº“

```python
# æ•°æ®å¤„ç†
import json             # JSONæ•°æ®å¤„ç†
import re               # æ­£åˆ™è¡¨è¾¾å¼
import base64           # å›¾åƒç¼–ç 
from typing import *    # ç±»å‹æ³¨è§£

# å›¾åƒå¤„ç†
from PIL import Image   # å›¾åƒæ“ä½œå’Œå‹ç¼©
import pillow-heif      # HEIFæ ¼å¼æ”¯æŒ

# ç½‘ç»œå’ŒAPI
import requests         # åŒæ­¥HTTPè¯·æ±‚
import aiohttp          # å¼‚æ­¥HTTPè¯·æ±‚

# æ•°æ®å­˜å‚¨
import redis            # Rediså®¢æˆ·ç«¯
import sqlite3          # è½»é‡çº§æ•°æ®åº“ï¼ˆå¤‡ç”¨ï¼‰

# ç³»ç»Ÿå·¥å…·
import logging          # æ—¥å¿—ç³»ç»Ÿ
import os               # ç³»ç»Ÿç¯å¢ƒ
import pathlib          # è·¯å¾„æ“ä½œ
import datetime         # æ—¶é—´å¤„ç†
```

### é¡¹ç›®ç»“æ„è®¾è®¡

```
src/
â”œâ”€â”€ core/                   # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚   â”œâ”€â”€ agent.py           # æ™ºèƒ½ä½“åŸºç±»å’Œå®ç°
â”‚   â”œâ”€â”€ conversation.py    # å¯¹è¯ç®¡ç†å™¨
â”‚   â”œâ”€â”€ memory.py          # è®°å¿†ç³»ç»Ÿ
â”‚   â””â”€â”€ stream_handler.py  # æµå¼è¾“å‡ºå¤„ç†
â”œâ”€â”€ models/                # AIæ¨¡å‹æ¥å£å±‚
â”‚   â”œâ”€â”€ base.py           # æ¨¡å‹åŸºç±»
â”‚   â”œâ”€â”€ openrouter.py     # OpenRouteré›†æˆ
â”‚   â””â”€â”€ doubao.py         # è±†åŒ…APIé›†æˆ
â”œâ”€â”€ utils/                 # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ image.py          # å›¾åƒå¤„ç†å·¥å…·
â”‚   â”œâ”€â”€ colors.py         # ç»ˆç«¯é¢œè‰²è¾“å‡º
â”‚   â”œâ”€â”€ voting.py         # æŠ•ç¥¨ç®—æ³•
â”‚   â””â”€â”€ compression.py    # å›¾åƒå‹ç¼©
â”œâ”€â”€ config/               # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ settings.py       # ç³»ç»Ÿé…ç½®
â”‚   â””â”€â”€ prompts/          # AIæç¤ºè¯æ¨¡æ¿
â””â”€â”€ memory/               # è®°å¿†é€‚é…å™¨
    â”œâ”€â”€ redis_adapter.py  # Redisè®°å¿†å­˜å‚¨
    â””â”€â”€ global_memory.py  # å…¨å±€è®°å¿†ç®¡ç†
```

---

## ğŸ¤– AIæ¨¡å‹é›†æˆ

### ä¸¤é˜¶æ®µAIæ¶æ„

TableRoundé‡‡ç”¨åˆ›æ–°çš„ä¸¤é˜¶æ®µAIæ¨¡å‹æ¶æ„ï¼Œé’ˆå¯¹ä¸åŒä»»åŠ¡ä½¿ç”¨ä¸“é—¨ä¼˜åŒ–çš„æ¨¡å‹ï¼š

#### ç¬¬ä¸€é˜¶æ®µï¼šè§†è§‰ç†è§£
```python
# è§†è§‰æ¨¡å‹é…ç½®
self.vision_model = "google/gemini-2.0-flash-exp:free"

# å›¾åƒå¤„ç†æµç¨‹
async def _describe_image_with_vision_model(self, prompt: str, system_prompt: str, image_path: str) -> str:
    # 1. å›¾åƒå‹ç¼©ä¼˜åŒ–
    compressed_image_path = self.image_compressor.compress_for_api(image_path)
    
    # 2. Base64ç¼–ç 
    with open(compressed_image_path, "rb") as image_file:
        base64_image = base64.b64encode(image_file.read()).decode('utf-8')
    
    # 3. æ„å»ºå¤šæ¨¡æ€è¯·æ±‚
    messages = [{
        "role": "user",
        "content": [
            {"type": "text", "text": image_prompt},
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
        ]
    }]
```

#### ç¬¬äºŒé˜¶æ®µï¼šå¯¹è¯ç”Ÿæˆ
```python
# å¯¹è¯æ¨¡å‹é…ç½®
self.chat_model = "deepseek/deepseek-r1-0528:free"

# åŸºäºå›¾åƒæè¿°çš„å¯¹è¯ç”Ÿæˆ
async def _generate_with_chat_model(self, prompt: str, system_prompt: str, image_description: str) -> str:
    enhanced_prompt = f"åŸºäºä»¥ä¸‹å›¾åƒæè¿°æ¥å›ç­”é—®é¢˜ï¼š\n\nå›¾åƒæè¿°ï¼š{image_description}\n\né—®é¢˜ï¼š{prompt}"
```

### æ”¯æŒçš„AIæä¾›å•†

#### 1. OpenRouter (ä¸»è¦)
- **æ¨¡å‹èŒƒå›´**ï¼š50+ å¼€æºå’Œå•†ä¸šæ¨¡å‹
- **ç‰¹ç‚¹**ï¼šç»Ÿä¸€APIæ¥å£ï¼Œæˆæœ¬ä¼˜åŒ–
- **ä½¿ç”¨åœºæ™¯**ï¼šå¯¹è¯ç”Ÿæˆã€æ–‡æœ¬å¤„ç†ã€è§†è§‰ç†è§£

#### 2. Google Gemini
- **æ¨¡å‹**ï¼šgemini-2.0-flash-exp
- **ç‰¹ç‚¹**ï¼šå¼ºå¤§çš„å¤šæ¨¡æ€èƒ½åŠ›
- **ä½¿ç”¨åœºæ™¯**ï¼šå›¾åƒç†è§£ã€è§†è§‰é—®ç­”

#### 3. DeepSeek
- **æ¨¡å‹**ï¼šdeepseek-r1-0528
- **ç‰¹ç‚¹**ï¼šæ¨ç†èƒ½åŠ›å¼ºï¼Œä¸­æ–‡æ”¯æŒå¥½
- **ä½¿ç”¨åœºæ™¯**ï¼šå¤æ‚å¯¹è¯ã€é€»è¾‘æ¨ç†

#### 4. è±†åŒ…API (å­—èŠ‚è·³åŠ¨)
- **æ¨¡å‹**ï¼šdoubao-seedream-3-0-t2i
- **ç‰¹ç‚¹**ï¼šå›¾åƒç”Ÿæˆä¸“ç”¨
- **ä½¿ç”¨åœºæ™¯**ï¼šåˆ›æ„å›¾åƒç”Ÿæˆ

### APIè°ƒç”¨ä¼˜åŒ–

```python
# ç»Ÿä¸€çš„APIè°ƒç”¨æ¥å£
class BaseModel:
    async def generate(self, prompt: str, system_prompt: str = "") -> str:
        """ç»Ÿä¸€çš„æ–‡æœ¬ç”Ÿæˆæ¥å£"""
        
    async def generate_with_image(self, prompt: str, system_prompt: str, image_path: str) -> str:
        """ç»Ÿä¸€çš„å›¾åƒç†è§£æ¥å£"""
        
    async def generate_stream(self, prompt: str, system_prompt: str = "", callback=None) -> str:
        """ç»Ÿä¸€çš„æµå¼ç”Ÿæˆæ¥å£"""

# é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
async def _make_request_with_retry(self, url: str, data: dict, max_retries: int = 3):
    for attempt in range(max_retries):
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=data, headers=headers) as response:
                    if response.status == 200:
                        return await response.json()
        except Exception as e:
            if attempt == max_retries - 1:
                raise e
            await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
```

---

## ğŸ’¾ æ•°æ®å­˜å‚¨ä¸ç¼“å­˜

### Redis åˆ†å¸ƒå¼ç¼“å­˜

TableRoundä½¿ç”¨Redisä½œä¸ºä¸»è¦çš„æ•°æ®å­˜å‚¨å’Œç¼“å­˜è§£å†³æ–¹æ¡ˆï¼š

#### è®°å¿†ç³»ç»Ÿæ¶æ„
```python
# Redisè¿æ¥é…ç½®
class RedisMemoryAdapter:
    def __init__(self, host='localhost', port=6379, db=0):
        self.redis_client = redis.Redis(
            host=host, 
            port=port, 
            db=db,
            decode_responses=True,
            socket_connect_timeout=5,
            socket_timeout=5
        )
```

#### æ•°æ®ç»“æ„è®¾è®¡
```python
# æ™ºèƒ½ä½“è®°å¿†å­˜å‚¨
agent_memory:{agent_id} = {
    "conversations": [...],      # å¯¹è¯å†å²
    "keywords": [...],          # å…³é”®è¯è®°å½•
    "role_switches": [...],     # è§’è‰²è½¬æ¢å†å²
    "image_stories": [...]      # å›¾åƒæ•…äº‹
}

# å…¨å±€ä¼šè®®è®°å¿†
global_memory:{session_id} = {
    "participants": [...],      # å‚ä¸è€…åˆ—è¡¨
    "stage": "discussion",      # å½“å‰é˜¶æ®µ
    "context": [...],          # å…¨å±€ä¸Šä¸‹æ–‡
    "timeline": [...]          # æ—¶é—´çº¿è®°å½•
}
```

#### ç¼“å­˜ç­–ç•¥
- **TTLè®¾ç½®**ï¼šä¼šè¯æ•°æ®24å°æ—¶è¿‡æœŸ
- **å†…å­˜ä¼˜åŒ–**ï¼šå¤§å‹æ•°æ®ä½¿ç”¨å‹ç¼©å­˜å‚¨
- **æŒä¹…åŒ–**ï¼šå…³é”®æ•°æ®å®šæœŸå¤‡ä»½åˆ°æ–‡ä»¶

### æ–‡ä»¶å­˜å‚¨ç³»ç»Ÿ

```python
# ç›®å½•ç»“æ„
data/
â”œâ”€â”€ images/                 # å›¾åƒæ–‡ä»¶
â”‚   â”œâ”€â”€ original/          # åŸå§‹å›¾åƒ
â”‚   â”œâ”€â”€ compressed/        # å‹ç¼©å›¾åƒ
â”‚   â””â”€â”€ generated/         # AIç”Ÿæˆå›¾åƒ
â”œâ”€â”€ memories/              # è®°å¿†å¤‡ä»½
â”œâ”€â”€ logs/                  # æ—¥å¿—æ–‡ä»¶
â””â”€â”€ exports/               # å¯¼å‡ºæ•°æ®
```

---

## ğŸ–¼ï¸ å›¾åƒå¤„ç†æŠ€æœ¯

### æ™ºèƒ½å›¾åƒå‹ç¼©

TableRoundå®ç°äº†è‡ªé€‚åº”çš„å›¾åƒå‹ç¼©ç³»ç»Ÿï¼Œé’ˆå¯¹AIæ¨¡å‹ä¼˜åŒ–ï¼š

```python
class ImageCompressor:
    def __init__(self, max_width=800, max_height=800, max_file_size_mb=1.5, quality=85):
        self.max_width = max_width
        self.max_height = max_height
        self.max_file_size_mb = max_file_size_mb
        self.quality = quality
    
    def compress_for_api(self, image_path: str) -> str:
        """ä¸ºAPIè°ƒç”¨ä¼˜åŒ–å›¾åƒ"""
        # 1. æ ¼å¼æ£€æµ‹å’Œè½¬æ¢
        # 2. å°ºå¯¸è°ƒæ•´
        # 3. è´¨é‡å‹ç¼©
        # 4. æ–‡ä»¶å¤§å°æ§åˆ¶
```

#### å‹ç¼©ç®—æ³•ç‰¹ç‚¹
- **è‡ªé€‚åº”å°ºå¯¸**ï¼šæ ¹æ®åŸå›¾æ¯”ä¾‹æ™ºèƒ½è°ƒæ•´
- **è´¨é‡å¹³è¡¡**ï¼šåœ¨æ–‡ä»¶å¤§å°å’Œå›¾åƒè´¨é‡é—´æ‰¾åˆ°æœ€ä½³å¹³è¡¡
- **æ ¼å¼ä¼˜åŒ–**ï¼šè‡ªåŠ¨è½¬æ¢ä¸ºæœ€é€‚åˆçš„æ ¼å¼
- **æ‰¹é‡å¤„ç†**ï¼šæ”¯æŒå¤šå›¾åƒå¹¶è¡Œå‹ç¼©

### æ”¯æŒçš„å›¾åƒæ ¼å¼
- **è¾“å…¥æ ¼å¼**ï¼šJPEG, PNG, GIF, WebP, HEIF, BMP
- **è¾“å‡ºæ ¼å¼**ï¼šJPEG (ä¼˜åŒ–), PNG (é€æ˜)
- **ç‰¹æ®Šå¤„ç†**ï¼šHEIFæ ¼å¼è‡ªåŠ¨è½¬æ¢ï¼Œé€æ˜èƒŒæ™¯ä¿æŒ

---

## ğŸŒ ç½‘ç»œé€šä¿¡

### å¼‚æ­¥HTTPå®¢æˆ·ç«¯

```python
# aiohttpé…ç½®
async def make_api_request(self, url: str, data: dict):
    timeout = aiohttp.ClientTimeout(total=60, connect=10)
    connector = aiohttp.TCPConnector(
        limit=100,              # è¿æ¥æ± å¤§å°
        limit_per_host=30,      # æ¯ä¸ªä¸»æœºçš„è¿æ¥æ•°
        keepalive_timeout=30,   # ä¿æŒè¿æ¥æ—¶é—´
        enable_cleanup_closed=True
    )
    
    async with aiohttp.ClientSession(
        timeout=timeout,
        connector=connector,
        headers=self.default_headers
    ) as session:
        async with session.post(url, json=data) as response:
            return await response.json()
```

### æµå¼æ•°æ®å¤„ç†

```python
# æµå¼å“åº”å¤„ç†
async def handle_stream_response(self, response):
    async for line in response.content:
        line = line.decode('utf-8').strip()
        if line.startswith('data: ') and line != 'data: [DONE]':
            data_str = line[6:]
            try:
                data = json.loads(data_str)
                if 'choices' in data:
                    delta = data['choices'][0]['delta']
                    if 'content' in delta:
                        yield delta['content']
            except json.JSONDecodeError:
                continue
```

### APIå®‰å…¨æœºåˆ¶

- **APIå¯†é’¥ç®¡ç†**ï¼šç¯å¢ƒå˜é‡å­˜å‚¨ï¼Œè¿è¡Œæ—¶åŠ è½½
- **è¯·æ±‚é™æµ**ï¼šæ™ºèƒ½é‡è¯•å’Œé€€é¿ç­–ç•¥
- **é”™è¯¯å¤„ç†**ï¼šè¯¦ç»†çš„é”™è¯¯åˆ†ç±»å’Œæ¢å¤æœºåˆ¶
- **è¶…æ—¶æ§åˆ¶**ï¼šå¤šå±‚æ¬¡çš„è¶…æ—¶ä¿æŠ¤

---

## ğŸ› ï¸ å¼€å‘å·¥å…·ä¸ç¯å¢ƒ

### å¼€å‘ç¯å¢ƒé…ç½®

```bash
# Pythonç¯å¢ƒ
Python 3.8+
pip 21.0+

# è™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# ä¾èµ–ç®¡ç†
pip install -r requirements.txt
```

### ä»£ç è´¨é‡å·¥å…·

```python
# ç±»å‹æ³¨è§£
from typing import List, Dict, Optional, Union, Callable, Any, Tuple

# ç¤ºä¾‹ï¼šä¸¥æ ¼çš„ç±»å‹å®šä¹‰
class Agent:
    def __init__(self, 
                 name: str, 
                 agent_type: str, 
                 model: BaseModel,
                 memory_adapter: Optional[MemoryAdapter] = None) -> None:
        self.name: str = name
        self.type: str = agent_type
        self.model: BaseModel = model
        self.memory: Optional[MemoryAdapter] = memory_adapter
    
    async def discuss(self, topic: str, context: str) -> str:
        """æ™ºèƒ½ä½“è®¨è®ºæ–¹æ³•"""
        pass
```

### æ—¥å¿—ç³»ç»Ÿ

```python
# å¤šå±‚æ¬¡æ—¥å¿—é…ç½®
import logging
from logging.handlers import RotatingFileHandler

# æ—¥å¿—æ ¼å¼
LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# æ–‡ä»¶è½®è½¬
file_handler = RotatingFileHandler(
    'logs/app.log',
    maxBytes=10*1024*1024,  # 10MB
    backupCount=5
)

# åˆ†ç±»æ—¥å¿—
loggers = {
    'conversation': logging.getLogger('conversation'),
    'agent': logging.getLogger('agent'),
    'model': logging.getLogger('model'),
    'memory': logging.getLogger('memory')
}
```

### é…ç½®ç®¡ç†

```python
# ç¯å¢ƒé…ç½®
class Settings:
    def __init__(self):
        # AIé…ç½®
        self.ai_provider = os.getenv("AI_PROVIDER", "openrouter")
        self.ai_model = os.getenv("AI_MODEL", "deepseek/deepseek-r1-0528:free")
        self.openrouter_api_key = os.getenv("OPENROUTER_API_KEY")
        
        # Redisé…ç½®
        self.redis_host = os.getenv("REDIS_HOST", "localhost")
        self.redis_port = int(os.getenv("REDIS_PORT", "6379"))
        
        # ç³»ç»Ÿé…ç½®
        self.max_turns = int(os.getenv("MAX_TURNS", "1"))
        self.max_keywords = int(os.getenv("MAX_KEYWORDS", "10"))
```

---

## ğŸš€ éƒ¨ç½²ä¸è¿ç»´

### å®¹å™¨åŒ–éƒ¨ç½²

```dockerfile
# Dockerfileç¤ºä¾‹
FROM python:3.9-slim

WORKDIR /app

# ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    redis-server \
    && rm -rf /var/lib/apt/lists/*

# Pythonä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# åº”ç”¨ä»£ç 
COPY . .

# å¯åŠ¨è„šæœ¬
CMD ["python", "run.py"]
```

### Docker Composeé…ç½®

```yaml
version: '3.8'
services:
  tableround:
    build: .
    ports:
      - "8000:8000"
    environment:
      - REDIS_HOST=redis
      - AI_PROVIDER=openrouter
    depends_on:
      - redis
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
  
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

volumes:
  redis_data:
```

### ç›‘æ§å’Œç»´æŠ¤

```python
# å¥åº·æ£€æŸ¥
async def health_check():
    checks = {
        "redis": await check_redis_connection(),
        "ai_models": await check_ai_models(),
        "disk_space": check_disk_space(),
        "memory_usage": check_memory_usage()
    }
    return checks

# æ€§èƒ½ç›‘æ§
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            "api_calls": 0,
            "response_times": [],
            "error_count": 0,
            "memory_usage": []
        }
    
    async def log_api_call(self, duration: float, success: bool):
        self.metrics["api_calls"] += 1
        self.metrics["response_times"].append(duration)
        if not success:
            self.metrics["error_count"] += 1
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### å¼‚æ­¥å¹¶å‘ä¼˜åŒ–

```python
# æ™ºèƒ½ä½“å¹¶å‘å¤„ç†
async def process_agents_concurrently(self, agents: List[Agent], task: str):
    tasks = [agent.process_task(task) for agent in agents]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # å¤„ç†å¼‚å¸¸å’Œç»“æœ
    successful_results = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            self.logger.error(f"Agent {agents[i].name} failed: {result}")
        else:
            successful_results.append(result)
    
    return successful_results
```

### ç¼“å­˜ç­–ç•¥

```python
# å¤šå±‚ç¼“å­˜
class CacheManager:
    def __init__(self):
        self.memory_cache = {}  # å†…å­˜ç¼“å­˜
        self.redis_cache = redis.Redis()  # Redisç¼“å­˜
    
    async def get(self, key: str):
        # 1. æ£€æŸ¥å†…å­˜ç¼“å­˜
        if key in self.memory_cache:
            return self.memory_cache[key]
        
        # 2. æ£€æŸ¥Redisç¼“å­˜
        value = await self.redis_cache.get(key)
        if value:
            self.memory_cache[key] = value  # å›å¡«å†…å­˜ç¼“å­˜
            return value
        
        return None
```

### å›¾åƒå¤„ç†ä¼˜åŒ–

```python
# æ‰¹é‡å›¾åƒå¤„ç†
async def process_images_batch(self, image_paths: List[str]):
    semaphore = asyncio.Semaphore(5)  # é™åˆ¶å¹¶å‘æ•°
    
    async def process_single_image(path: str):
        async with semaphore:
            return await self.compress_image(path)
    
    tasks = [process_single_image(path) for path in image_paths]
    return await asyncio.gather(*tasks)
```

---

## ğŸ”’ å®‰å…¨è€ƒè™‘

### APIå®‰å…¨

```python
# APIå¯†é’¥å®‰å…¨ç®¡ç†
class SecureConfig:
    def __init__(self):
        self.api_keys = {}
        self.load_encrypted_keys()
    
    def get_api_key(self, provider: str) -> str:
        key = os.getenv(f"{provider.upper()}_API_KEY")
        if not key:
            raise ValueError(f"API key for {provider} not found")
        return key
    
    def validate_api_key(self, key: str) -> bool:
        # éªŒè¯APIå¯†é’¥æ ¼å¼
        return bool(re.match(r'^[a-zA-Z0-9\-_]{20,}$', key))
```

### è¾“å…¥éªŒè¯

```python
# ç”¨æˆ·è¾“å…¥å®‰å…¨éªŒè¯
class InputValidator:
    @staticmethod
    def validate_image_path(path: str) -> bool:
        # è·¯å¾„éå†æ”»å‡»é˜²æŠ¤
        if '..' in path or path.startswith('/'):
            return False
        
        # æ–‡ä»¶ç±»å‹éªŒè¯
        allowed_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.webp'}
        return Path(path).suffix.lower() in allowed_extensions
    
    @staticmethod
    def sanitize_text_input(text: str) -> str:
        # ç§»é™¤æ½œåœ¨çš„æ¶æ„å­—ç¬¦
        return re.sub(r'[<>"\']', '', text)[:1000]  # é™åˆ¶é•¿åº¦
```

### æ•°æ®éšç§

```python
# æ•æ„Ÿæ•°æ®å¤„ç†
class PrivacyManager:
    def __init__(self):
        self.sensitive_patterns = [
            r'\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b',  # ä¿¡ç”¨å¡å·
            r'\b\d{3}-\d{2}-\d{4}\b',  # ç¤¾ä¼šå®‰å…¨å·
            r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'  # é‚®ç®±
        ]
    
    def mask_sensitive_data(self, text: str) -> str:
        for pattern in self.sensitive_patterns:
            text = re.sub(pattern, '[REDACTED]', text)
        return text
```

---

## ğŸ“Š æŠ€æœ¯æŒ‡æ ‡

### æ€§èƒ½æŒ‡æ ‡
- **å“åº”æ—¶é—´**ï¼šå¹³å‡ < 3ç§’
- **å¹¶å‘å¤„ç†**ï¼šæ”¯æŒ10+æ™ºèƒ½ä½“åŒæ—¶å·¥ä½œ
- **å†…å­˜ä½¿ç”¨**ï¼š< 512MB (ä¸å«æ¨¡å‹)
- **å›¾åƒå¤„ç†**ï¼šå‹ç¼©ç‡60-80%ï¼Œå¤„ç†æ—¶é—´ < 1ç§’

### å¯é æ€§æŒ‡æ ‡
- **APIæˆåŠŸç‡**ï¼š> 99%
- **é”™è¯¯æ¢å¤**ï¼šè‡ªåŠ¨é‡è¯•3æ¬¡
- **æ•°æ®ä¸€è‡´æ€§**ï¼šRedisäº‹åŠ¡ä¿è¯
- **ç³»ç»Ÿå¯ç”¨æ€§**ï¼š> 99.9%

### æ‰©å±•æ€§æŒ‡æ ‡
- **æ™ºèƒ½ä½“æ‰©å±•**ï¼šæ”¯æŒåŠ¨æ€æ·»åŠ æ–°è§’è‰²
- **æ¨¡å‹æ‰©å±•**ï¼šæ’ä»¶åŒ–AIæ¨¡å‹é›†æˆ
- **åŠŸèƒ½æ‰©å±•**ï¼šæ¨¡å—åŒ–æ¶æ„æ”¯æŒ
- **éƒ¨ç½²æ‰©å±•**ï¼šå®¹å™¨åŒ–æ°´å¹³æ‰©å±•

---

## ğŸ”® æŠ€æœ¯å‘å±•æ–¹å‘

### çŸ­æœŸè§„åˆ’
1. **WebSocketæ”¯æŒ**ï¼šå®æ—¶åŒå‘é€šä¿¡
2. **Webç•Œé¢**ï¼šåŸºäºReactçš„ç°ä»£åŒ–UI
3. **æ¨¡å‹å¾®è°ƒ**ï¼šé’ˆå¯¹ç‰¹å®šåœºæ™¯çš„æ¨¡å‹ä¼˜åŒ–
4. **APIç½‘å…³**ï¼šç»Ÿä¸€çš„APIç®¡ç†å’Œé™æµ

### é•¿æœŸè§„åˆ’
1. **åˆ†å¸ƒå¼æ¶æ„**ï¼šå¾®æœåŠ¡åŒ–æ”¹é€ 
2. **AI Agentç¼–æ’**ï¼šæ›´å¤æ‚çš„æ™ºèƒ½ä½“å·¥ä½œæµ
3. **å¤šæ¨¡æ€èåˆ**ï¼šæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘çš„ç»Ÿä¸€å¤„ç†
4. **è¾¹ç¼˜è®¡ç®—**ï¼šæœ¬åœ°æ¨¡å‹éƒ¨ç½²å’Œæ¨ç†

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [é¡¹ç›®æ¶æ„å¸ƒå±€](docs/é¡¹ç›®æ¶æ„å¸ƒå±€.md)
- [APIæ¥å£æ–‡æ¡£](docs/APIæ–‡æ¡£.md)
- [éƒ¨ç½²æŒ‡å—](docs/éƒ¨ç½²æŒ‡å—.md)
- [å¼€å‘æŒ‡å—](docs/å¼€å‘æŒ‡å—.md)
- [æ•…éšœæ’é™¤](docs/æ•…éšœæ’é™¤.md)

---

---

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### å•å…ƒæµ‹è¯•

```python
# æµ‹è¯•æ¡†æ¶ï¼špytest + asyncio
import pytest
import asyncio
from unittest.mock import AsyncMock, patch

class TestAgent:
    @pytest.mark.asyncio
    async def test_agent_discussion(self):
        # æ¨¡æ‹ŸAIæ¨¡å‹å“åº”
        mock_model = AsyncMock()
        mock_model.generate.return_value = "æµ‹è¯•å›å¤"

        agent = Agent("æµ‹è¯•æ™ºèƒ½ä½“", "consumer", mock_model)
        result = await agent.discuss("æµ‹è¯•ä¸»é¢˜", "æµ‹è¯•ä¸Šä¸‹æ–‡")

        assert result == "æµ‹è¯•å›å¤"
        mock_model.generate.assert_called_once()

    @pytest.mark.asyncio
    async def test_image_processing(self):
        with patch('src.utils.image.ImageCompressor') as mock_compressor:
            mock_compressor.compress_for_api.return_value = "compressed_path.jpg"

            result = await process_image("test_image.jpg")
            assert result is not None
```

### é›†æˆæµ‹è¯•

```python
# APIé›†æˆæµ‹è¯•
class TestAPIIntegration:
    @pytest.mark.asyncio
    async def test_openrouter_integration(self):
        """æµ‹è¯•OpenRouter APIé›†æˆ"""
        model = OpenRouterModel("deepseek/deepseek-r1-0528:free", api_key="test_key")

        with patch('aiohttp.ClientSession.post') as mock_post:
            mock_response = AsyncMock()
            mock_response.status = 200
            mock_response.json.return_value = {
                "choices": [{"message": {"content": "æµ‹è¯•å“åº”"}}]
            }
            mock_post.return_value.__aenter__.return_value = mock_response

            result = await model.generate("æµ‹è¯•æç¤º", "ç³»ç»Ÿæç¤º")
            assert result == "æµ‹è¯•å“åº”"

    @pytest.mark.asyncio
    async def test_redis_memory_integration(self):
        """æµ‹è¯•Redisè®°å¿†ç³»ç»Ÿé›†æˆ"""
        memory = RedisMemoryAdapter()

        # æµ‹è¯•å­˜å‚¨å’Œæ£€ç´¢
        await memory.add_memory("test_agent", "conversation", {"content": "æµ‹è¯•å¯¹è¯"})
        memories = await memory.get_relevant_memories("test_agent", "æµ‹è¯•")

        assert len(memories) > 0
        assert "æµ‹è¯•å¯¹è¯" in str(memories)
```

### æ€§èƒ½æµ‹è¯•

```python
# è´Ÿè½½æµ‹è¯•
import time
import statistics

class TestPerformance:
    @pytest.mark.asyncio
    async def test_concurrent_agents(self):
        """æµ‹è¯•å¹¶å‘æ™ºèƒ½ä½“æ€§èƒ½"""
        agents = [create_test_agent(f"agent_{i}") for i in range(10)]

        start_time = time.time()
        tasks = [agent.discuss("æ€§èƒ½æµ‹è¯•", "å¹¶å‘æµ‹è¯•") for agent in agents]
        results = await asyncio.gather(*tasks)
        end_time = time.time()

        # éªŒè¯æ‰€æœ‰æ™ºèƒ½ä½“éƒ½æˆåŠŸå“åº”
        assert len(results) == 10
        assert all(result for result in results)

        # éªŒè¯å“åº”æ—¶é—´åœ¨å¯æ¥å—èŒƒå›´å†…
        total_time = end_time - start_time
        assert total_time < 30  # 30ç§’å†…å®Œæˆ

    def test_image_compression_performance(self):
        """æµ‹è¯•å›¾åƒå‹ç¼©æ€§èƒ½"""
        compressor = ImageCompressor()
        test_images = ["test1.jpg", "test2.png", "test3.gif"]

        compression_times = []
        for image_path in test_images:
            start_time = time.time()
            compressed_path = compressor.compress_for_api(image_path)
            end_time = time.time()

            compression_times.append(end_time - start_time)

            # éªŒè¯å‹ç¼©æ•ˆæœ
            original_size = os.path.getsize(image_path)
            compressed_size = os.path.getsize(compressed_path)
            compression_ratio = compressed_size / original_size

            assert compression_ratio < 0.8  # å‹ç¼©ç‡è‡³å°‘20%

        # éªŒè¯å¹³å‡å‹ç¼©æ—¶é—´
        avg_time = statistics.mean(compression_times)
        assert avg_time < 2.0  # å¹³å‡å‹ç¼©æ—¶é—´å°äº2ç§’
```

---

## ğŸ”§ è°ƒè¯•å’Œæ•…éšœæ’é™¤

### æ—¥å¿—åˆ†æå·¥å…·

```python
# æ—¥å¿—åˆ†æå™¨
class LogAnalyzer:
    def __init__(self, log_file_path: str):
        self.log_file_path = log_file_path
        self.patterns = {
            'error': r'ERROR - (.+)',
            'api_call': r'INFO - (APIè°ƒç”¨|APIè¯·æ±‚)',
            'performance': r'INFO - (å“åº”æ—¶é—´|å¤„ç†æ—¶é—´): (\d+\.?\d*)ms'
        }

    def analyze_errors(self, hours: int = 24) -> Dict[str, int]:
        """åˆ†ææœ€è¿‘Nå°æ—¶çš„é”™è¯¯"""
        error_counts = {}
        cutoff_time = datetime.now() - timedelta(hours=hours)

        with open(self.log_file_path, 'r', encoding='utf-8') as f:
            for line in f:
                if 'ERROR' in line:
                    # æå–æ—¶é—´æˆ³å’Œé”™è¯¯ä¿¡æ¯
                    timestamp_match = re.search(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})', line)
                    if timestamp_match:
                        timestamp = datetime.strptime(timestamp_match.group(1), '%Y-%m-%d %H:%M:%S')
                        if timestamp > cutoff_time:
                            error_match = re.search(self.patterns['error'], line)
                            if error_match:
                                error_type = error_match.group(1).split(':')[0]
                                error_counts[error_type] = error_counts.get(error_type, 0) + 1

        return error_counts

    def get_performance_metrics(self) -> Dict[str, float]:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        response_times = []

        with open(self.log_file_path, 'r', encoding='utf-8') as f:
            for line in f:
                perf_match = re.search(self.patterns['performance'], line)
                if perf_match:
                    response_time = float(perf_match.group(2))
                    response_times.append(response_time)

        if response_times:
            return {
                'avg_response_time': statistics.mean(response_times),
                'max_response_time': max(response_times),
                'min_response_time': min(response_times),
                'p95_response_time': statistics.quantiles(response_times, n=20)[18]  # 95th percentile
            }
        return {}
```

### å¥åº·æ£€æŸ¥ç³»ç»Ÿ

```python
# ç³»ç»Ÿå¥åº·æ£€æŸ¥
class HealthChecker:
    def __init__(self):
        self.checks = {
            'redis': self._check_redis,
            'ai_models': self._check_ai_models,
            'disk_space': self._check_disk_space,
            'memory_usage': self._check_memory_usage,
            'api_endpoints': self._check_api_endpoints
        }

    async def run_all_checks(self) -> Dict[str, Dict[str, Any]]:
        """è¿è¡Œæ‰€æœ‰å¥åº·æ£€æŸ¥"""
        results = {}

        for check_name, check_func in self.checks.items():
            try:
                start_time = time.time()
                result = await check_func()
                end_time = time.time()

                results[check_name] = {
                    'status': 'healthy' if result['success'] else 'unhealthy',
                    'details': result,
                    'check_duration': end_time - start_time
                }
            except Exception as e:
                results[check_name] = {
                    'status': 'error',
                    'error': str(e),
                    'check_duration': 0
                }

        return results

    async def _check_redis(self) -> Dict[str, Any]:
        """æ£€æŸ¥Redisè¿æ¥"""
        try:
            redis_client = redis.Redis(host='localhost', port=6379, db=0)
            redis_client.ping()

            # æ£€æŸ¥å†…å­˜ä½¿ç”¨
            info = redis_client.info('memory')
            memory_usage = info['used_memory'] / info['maxmemory'] if info['maxmemory'] > 0 else 0

            return {
                'success': True,
                'memory_usage_percent': memory_usage * 100,
                'connected_clients': redis_client.info('clients')['connected_clients']
            }
        except Exception as e:
            return {'success': False, 'error': str(e)}

    async def _check_ai_models(self) -> Dict[str, Any]:
        """æ£€æŸ¥AIæ¨¡å‹å¯ç”¨æ€§"""
        model_status = {}

        # æµ‹è¯•OpenRouter
        try:
            model = OpenRouterModel("deepseek/deepseek-r1-0528:free", api_key=os.getenv("OPENROUTER_API_KEY"))
            test_response = await model.generate("æµ‹è¯•", "ç®€çŸ­å›å¤")
            model_status['openrouter'] = {'status': 'available', 'response_length': len(test_response)}
        except Exception as e:
            model_status['openrouter'] = {'status': 'unavailable', 'error': str(e)}

        # æµ‹è¯•è±†åŒ…API
        try:
            # ç®€å•çš„APIè¿é€šæ€§æµ‹è¯•
            model_status['doubao'] = {'status': 'available'}
        except Exception as e:
            model_status['doubao'] = {'status': 'unavailable', 'error': str(e)}

        return {
            'success': all(status['status'] == 'available' for status in model_status.values()),
            'models': model_status
        }
```

### é”™è¯¯æ¢å¤æœºåˆ¶

```python
# è‡ªåŠ¨é”™è¯¯æ¢å¤
class ErrorRecoveryManager:
    def __init__(self):
        self.recovery_strategies = {
            'api_timeout': self._recover_from_api_timeout,
            'redis_connection_lost': self._recover_from_redis_failure,
            'model_overload': self._recover_from_model_overload,
            'memory_exhaustion': self._recover_from_memory_issue
        }
        self.circuit_breakers = {}

    async def handle_error(self, error_type: str, context: Dict[str, Any]) -> bool:
        """å¤„ç†é”™è¯¯å¹¶å°è¯•æ¢å¤"""
        if error_type in self.recovery_strategies:
            try:
                recovery_func = self.recovery_strategies[error_type]
                success = await recovery_func(context)

                if success:
                    logging.info(f"æˆåŠŸä»é”™è¯¯ {error_type} ä¸­æ¢å¤")
                    return True
                else:
                    logging.warning(f"æ— æ³•ä»é”™è¯¯ {error_type} ä¸­æ¢å¤")
                    return False
            except Exception as e:
                logging.error(f"é”™è¯¯æ¢å¤è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
                return False
        else:
            logging.warning(f"æœªçŸ¥é”™è¯¯ç±»å‹: {error_type}")
            return False

    async def _recover_from_api_timeout(self, context: Dict[str, Any]) -> bool:
        """ä»APIè¶…æ—¶ä¸­æ¢å¤"""
        # å®ç°æŒ‡æ•°é€€é¿é‡è¯•
        max_retries = 3
        base_delay = 1

        for attempt in range(max_retries):
            try:
                delay = base_delay * (2 ** attempt)
                await asyncio.sleep(delay)

                # é‡æ–°å°è¯•APIè°ƒç”¨
                result = await context['retry_function']()
                if result:
                    return True
            except Exception as e:
                logging.warning(f"é‡è¯• {attempt + 1} å¤±è´¥: {e}")

        return False

    async def _recover_from_redis_failure(self, context: Dict[str, Any]) -> bool:
        """ä»Redisè¿æ¥å¤±è´¥ä¸­æ¢å¤"""
        try:
            # å°è¯•é‡æ–°è¿æ¥Redis
            redis_client = redis.Redis(host='localhost', port=6379, db=0, socket_connect_timeout=5)
            redis_client.ping()

            # æ›´æ–°å…¨å±€Rediså®¢æˆ·ç«¯
            context['redis_client'] = redis_client
            return True
        except Exception as e:
            logging.error(f"Redisé‡è¿å¤±è´¥: {e}")

            # åˆ‡æ¢åˆ°æ–‡ä»¶å­˜å‚¨ä½œä¸ºå¤‡ç”¨
            logging.info("åˆ‡æ¢åˆ°æ–‡ä»¶å­˜å‚¨æ¨¡å¼")
            context['use_file_storage'] = True
            return True
```

---

## ğŸ“ˆ ç›‘æ§å’ŒæŒ‡æ ‡

### å®æ—¶ç›‘æ§ç³»ç»Ÿ

```python
# æ€§èƒ½ç›‘æ§
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            'api_calls_total': 0,
            'api_calls_success': 0,
            'api_calls_failed': 0,
            'response_times': [],
            'memory_usage_history': [],
            'active_sessions': 0,
            'image_processing_count': 0
        }
        self.start_time = time.time()

    def record_api_call(self, duration: float, success: bool, endpoint: str):
        """è®°å½•APIè°ƒç”¨æŒ‡æ ‡"""
        self.metrics['api_calls_total'] += 1
        if success:
            self.metrics['api_calls_success'] += 1
        else:
            self.metrics['api_calls_failed'] += 1

        self.metrics['response_times'].append({
            'timestamp': time.time(),
            'duration': duration,
            'endpoint': endpoint,
            'success': success
        })

        # ä¿æŒæœ€è¿‘1000æ¡è®°å½•
        if len(self.metrics['response_times']) > 1000:
            self.metrics['response_times'] = self.metrics['response_times'][-1000:]

    def get_current_metrics(self) -> Dict[str, Any]:
        """è·å–å½“å‰æ€§èƒ½æŒ‡æ ‡"""
        uptime = time.time() - self.start_time
        recent_responses = [r for r in self.metrics['response_times']
                          if time.time() - r['timestamp'] < 300]  # æœ€è¿‘5åˆ†é’Ÿ

        if recent_responses:
            avg_response_time = statistics.mean([r['duration'] for r in recent_responses])
            success_rate = len([r for r in recent_responses if r['success']]) / len(recent_responses)
        else:
            avg_response_time = 0
            success_rate = 1.0

        return {
            'uptime_seconds': uptime,
            'total_api_calls': self.metrics['api_calls_total'],
            'success_rate': success_rate,
            'avg_response_time_5min': avg_response_time,
            'active_sessions': self.metrics['active_sessions'],
            'memory_usage_mb': self._get_memory_usage(),
            'image_processing_count': self.metrics['image_processing_count']
        }

    def _get_memory_usage(self) -> float:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡"""
        import psutil
        process = psutil.Process()
        return process.memory_info().rss / 1024 / 1024  # MB
```

### å‘Šè­¦ç³»ç»Ÿ

```python
# å‘Šè­¦ç®¡ç†
class AlertManager:
    def __init__(self):
        self.alert_rules = {
            'high_error_rate': {
                'condition': lambda metrics: metrics.get('success_rate', 1.0) < 0.95,
                'message': 'é”™è¯¯ç‡è¿‡é«˜: {success_rate:.2%}',
                'severity': 'critical'
            },
            'slow_response': {
                'condition': lambda metrics: metrics.get('avg_response_time_5min', 0) > 10,
                'message': 'å“åº”æ—¶é—´è¿‡æ…¢: {avg_response_time_5min:.2f}ç§’',
                'severity': 'warning'
            },
            'high_memory_usage': {
                'condition': lambda metrics: metrics.get('memory_usage_mb', 0) > 1024,
                'message': 'å†…å­˜ä½¿ç”¨è¿‡é«˜: {memory_usage_mb:.1f}MB',
                'severity': 'warning'
            }
        }
        self.alert_history = []

    def check_alerts(self, metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        active_alerts = []

        for rule_name, rule in self.alert_rules.items():
            if rule['condition'](metrics):
                alert = {
                    'rule_name': rule_name,
                    'message': rule['message'].format(**metrics),
                    'severity': rule['severity'],
                    'timestamp': time.time(),
                    'metrics_snapshot': metrics.copy()
                }
                active_alerts.append(alert)

                # è®°å½•å‘Šè­¦å†å²
                self.alert_history.append(alert)

                # ä¿æŒæœ€è¿‘100æ¡å‘Šè­¦è®°å½•
                if len(self.alert_history) > 100:
                    self.alert_history = self.alert_history[-100:]

        return active_alerts

    async def send_alert(self, alert: Dict[str, Any]):
        """å‘é€å‘Šè­¦é€šçŸ¥"""
        # è¿™é‡Œå¯ä»¥é›†æˆé‚®ä»¶ã€çŸ­ä¿¡ã€Slackç­‰é€šçŸ¥æ–¹å¼
        logging.critical(f"ALERT [{alert['severity'].upper()}] {alert['message']}")

        # ç¤ºä¾‹ï¼šå‘é€åˆ°ç›‘æ§ç³»ç»Ÿ
        # await self.send_to_monitoring_system(alert)
```

---

**TableRoundæŠ€æœ¯æ ˆä½“ç°äº†ç°ä»£AIåº”ç”¨å¼€å‘çš„æœ€ä½³å®è·µï¼Œé€šè¿‡åˆç†çš„æ¶æ„è®¾è®¡ã€ä¼˜ç§€çš„æŠ€æœ¯é€‰å‹å’Œå®Œå–„çš„å·¥ç¨‹å®è·µï¼Œæ„å»ºäº†ä¸€ä¸ªé«˜æ€§èƒ½ã€å¯æ‰©å±•ã€æ˜“ç»´æŠ¤çš„å¤šæ™ºèƒ½ä½“äº¤äº’ç³»ç»Ÿã€‚**
