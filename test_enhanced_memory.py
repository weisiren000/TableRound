#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
å¢å¼ºè®°å¿†åŠŸèƒ½æµ‹è¯•
è®©è®°å¿†æ•ˆæœåœ¨å¯¹è¯ä¸­æ›´æ˜æ˜¾
"""

import asyncio
from src.core.memory_adapter import MemoryAdapter
from src.core.global_memory import GlobalMemory
from src.config.settings import Settings
from src.models.openrouter import OpenRouterModel


async def test_enhanced_memory_conversation():
    """æµ‹è¯•å¢å¼ºè®°å¿†åŠŸèƒ½åœ¨å¯¹è¯ä¸­çš„è¡¨ç°"""
    print("ğŸ§  æµ‹è¯•å¢å¼ºè®°å¿†åŠŸèƒ½...")
    print("=" * 60)
    
    # åˆå§‹åŒ–
    settings = Settings()
    # ä½¿ç”¨settingsçš„get_model_instanceæ–¹æ³•
    model = settings.get_model_instance("openrouter", "meta-llama/llama-4-maverick:free")
    
    # åˆ›å»ºè®°å¿†é€‚é…å™¨
    memory = MemoryAdapter("enhanced_test_agent", storage_type="auto", settings=settings)
    global_memory = GlobalMemory("enhanced_test_session", storage_type="auto")
    
    # 1. æ·»åŠ ä¸°å¯Œçš„ä¸ªäººè®°å¿†
    print("\n1. æ·»åŠ ä¸ªäººè®°å¿†...")
    personal_memories = [
        {
            "type": "introduction",
            "content": {
                "role": "craftsman",
                "name": "å¼ å¸ˆå‚…",
                "age": 65,
                "experience": "ä»äº‹è’™å¤æ—å‰ªçº¸è‰ºæœ¯45å¹´",
                "specialty": "ä¼ ç»Ÿè™è å‰ç¥¥çº¹æ ·è®¾è®¡",
                "philosophy": "ä¼ ç»Ÿä¸ç°ä»£ç›¸ç»“åˆï¼Œè®©å¤è€è‰ºæœ¯ç„•å‘æ–°ç”Ÿ",
                "memorable_quote": "æ¯ä¸€åˆ€éƒ½æ‰¿è½½ç€æ–‡åŒ–çš„ä¼ æ‰¿"
            }
        },
        {
            "type": "discussion",
            "content": {
                "topic": "ä¸­å›½ç²¾ç¥",
                "viewpoint": "ä¸­å›½ç²¾ç¥ä½“ç°åœ¨å·¥åŒ ç²¾ç¥ä¸­ï¼Œè¿½æ±‚å®Œç¾ï¼Œä¼ æ‰¿æ–‡åŒ–",
                "personal_story": "æˆ‘æ›¾ç»ä¸ºäº†ä¸€ä¸ªè™è çº¹æ ·çš„å¯¹ç§°æ€§ï¼Œåå¤ä¿®æ”¹äº†ä¸‰å¤©",
                "emotion": "è‡ªè±ªå’Œè´£ä»»æ„Ÿ"
            }
        },
        {
            "type": "preference",
            "content": {
                "favorite_materials": ["çº¢çº¸", "é‡‘ç®”", "å®£çº¸"],
                "design_style": "å¯¹ç§°ç¾å­¦ï¼Œå¯“æ„å‰ç¥¥",
                "target_audience": "å¹´è½»äººå’Œæ–‡åŒ–çˆ±å¥½è€…",
                "concerns": "å¦‚ä½•è®©ä¼ ç»Ÿè‰ºæœ¯è¢«ç°ä»£äººæ¥å—"
            }
        }
    ]
    
    for memory_data in personal_memories:
        await memory.add_memory(memory_data["type"], memory_data["content"])
        print(f"âœ… æ·»åŠ {memory_data['type']}è®°å¿†")
    
    # 2. æ·»åŠ å…¨å±€è®°å¿†ï¼ˆå…¶ä»–äººçš„å‘è¨€ï¼‰
    print("\n2. æ·»åŠ å…¨å±€è®°å¿†...")
    await global_memory.add_participant("consumer_zhang", "å¼ å¥³å£«", "consumer")
    await global_memory.add_participant("designer_li", "æè®¾è®¡å¸ˆ", "designer")
    
    # æ¨¡æ‹Ÿå…¶ä»–äººçš„å‘è¨€
    other_speeches = [
        {
            "agent_id": "consumer_zhang",
            "agent_name": "å¼ å¥³å£«",
            "content": "æˆ‘å¸Œæœ›å‰ªçº¸äº§å“èƒ½èå…¥ç°ä»£ç”Ÿæ´»ï¼Œæ¯”å¦‚åšæˆæ‰‹æœºå£³æˆ–è€…ä¹¦ç­¾",
            "speech_type": "discussion"
        },
        {
            "agent_id": "designer_li", 
            "agent_name": "æè®¾è®¡å¸ˆ",
            "content": "è™è çº¹æ ·ç¡®å®å¾ˆæœ‰æ–‡åŒ–å†…æ¶µï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ç°ä»£çš„è‰²å½©æ­é…æ¥å¸å¼•å¹´è½»äºº",
            "speech_type": "discussion"
        }
    ]
    
    for speech in other_speeches:
        await global_memory.record_speech(
            agent_id=speech["agent_id"],
            agent_name=speech["agent_name"],
            speech_type=speech["speech_type"],
            content=speech["content"],
            stage="discussion"
        )
        print(f"âœ… è®°å½•{speech['agent_name']}çš„å‘è¨€")
    
    # 3. æ¨¡æ‹Ÿæ™ºèƒ½ä½“å‚ä¸è®¨è®ºï¼ˆä½¿ç”¨è®°å¿†ï¼‰
    print("\n3. æ¨¡æ‹Ÿæ™ºèƒ½ä½“è®¨è®º...")
    topic = "å¦‚ä½•è®¾è®¡ç°ä»£åŒ–çš„å‰ªçº¸æ–‡åˆ›äº§å“"
    
    # è·å–ä¸ªäººè®°å¿†
    personal_memories_text = await memory.get_relevant_memories(topic, limit=5)
    
    # è·å–å…¨å±€ä¸Šä¸‹æ–‡
    global_context = await global_memory.get_current_context("enhanced_test_agent", max_context=10)
    
    # æ„å»ºå¢å¼ºprompt
    enhanced_prompt = f"""
ä½ æ˜¯å¼ å¸ˆå‚…ï¼Œä¸€ä½65å²çš„è’™å¤æ—å‰ªçº¸è‰ºæœ¯ä¼ æ‰¿äººï¼Œä»äº‹å‰ªçº¸è‰ºæœ¯45å¹´ã€‚

å½“å‰è®¨è®ºä¸»é¢˜ï¼š{topic}

ä½ çš„ä¸ªäººè®°å¿†å’Œç»éªŒï¼š
{chr(10).join(personal_memories_text) if personal_memories_text else "æš‚æ— ç›¸å…³è®°å¿†"}

ä¼šè®®ä¸­å…¶ä»–äººçš„å‘è¨€ï¼š
{global_context if global_context and "æš‚æ— " not in global_context else "æš‚æ— å…¶ä»–å‘è¨€"}

è¯·åŸºäºä½ çš„ä¸ªäººç»éªŒã€è®°å¿†å’Œå…¶ä»–äººçš„å‘è¨€ï¼Œå‘è¡¨ä½ çš„è§‚ç‚¹ã€‚è¦ä½“ç°å‡ºï¼š
1. ä½ çš„ä¸ªäººç»å†å’Œä¸“ä¸šèƒŒæ™¯
2. å¯¹å…¶ä»–äººå‘è¨€çš„å›åº”
3. å…·ä½“çš„å»ºè®®å’Œæƒ³æ³•
4. ä½ çš„æƒ…æ„Ÿå’Œæ€åº¦

è¯·ç”¨ç¬¬ä¸€äººç§°ï¼Œä»¥å¼ å¸ˆå‚…çš„èº«ä»½å›ç­”ï¼Œå­—æ•°æ§åˆ¶åœ¨200å­—å·¦å³ã€‚
"""
    
    print(f"\nğŸ“ æ„å»ºçš„å¢å¼ºprompt:")
    print(f"é•¿åº¦: {len(enhanced_prompt)} å­—ç¬¦")
    print(f"å†…å®¹é¢„è§ˆ:\n{enhanced_prompt[:500]}...")
    
    # ä½¿ç”¨AIæ¨¡å‹ç”Ÿæˆå›å¤
    print(f"\nğŸ¤– AIç”Ÿæˆå›å¤...")
    try:
        response = await model.generate(
            prompt=enhanced_prompt,
            system_prompt="ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ä¼ ç»Ÿæ‰‹å·¥è‰ºäººï¼Œå–„äºç»“åˆä¼ ç»Ÿæ–‡åŒ–å’Œç°ä»£éœ€æ±‚ã€‚"
        )
        
        print(f"\nğŸ’¬ å¼ å¸ˆå‚…çš„å›å¤:")
        print(f"{response}")
        
        # åˆ†æå›å¤ä¸­çš„è®°å¿†ä½“ç°
        print(f"\nğŸ“Š è®°å¿†ä½“ç°åˆ†æ:")
        memory_indicators = [
            ("ä¸ªäººç»å†", ["45å¹´", "65å²", "è’™å¤æ—", "å¼ å¸ˆå‚…"]),
            ("ä¸“ä¸šæœ¯è¯­", ["å‰ªçº¸", "è™è ", "çº¹æ ·", "å¯¹ç§°"]),
            ("å›åº”ä»–äºº", ["å¼ å¥³å£«", "æè®¾è®¡å¸ˆ", "æ‰‹æœºå£³", "ä¹¦ç­¾", "è‰²å½©"]),
            ("æƒ…æ„Ÿè¡¨è¾¾", ["è‡ªè±ª", "è´£ä»»", "ä¼ æ‰¿", "æ–‡åŒ–"])
        ]
        
        for category, keywords in memory_indicators:
            found_keywords = [kw for kw in keywords if kw in response]
            if found_keywords:
                print(f"âœ… {category}: {', '.join(found_keywords)}")
            else:
                print(f"âŒ {category}: æœªä½“ç°")
                
    except Exception as e:
        print(f"âŒ AIç”Ÿæˆå¤±è´¥: {str(e)}")
    
    # 4. å¯¹æ¯”æµ‹è¯•ï¼šä¸ä½¿ç”¨è®°å¿†çš„å›å¤
    print(f"\n4. å¯¹æ¯”æµ‹è¯•ï¼šä¸ä½¿ç”¨è®°å¿†çš„å›å¤")
    simple_prompt = f"è¯·å°±'{topic}'è¿™ä¸ªè¯é¢˜å‘è¡¨ä½ çš„è§‚ç‚¹ï¼Œå­—æ•°æ§åˆ¶åœ¨200å­—å·¦å³ã€‚"
    
    try:
        simple_response = await model.generate(
            prompt=simple_prompt,
            system_prompt="ä½ æ˜¯ä¸€ä½ä¼ ç»Ÿæ‰‹å·¥è‰ºäººã€‚"
        )
        
        print(f"\nğŸ’¬ æ— è®°å¿†ç‰ˆæœ¬çš„å›å¤:")
        print(f"{simple_response}")
        
        print(f"\nğŸ“Š å¯¹æ¯”åˆ†æ:")
        print(f"æœ‰è®°å¿†ç‰ˆæœ¬é•¿åº¦: {len(response)} å­—ç¬¦")
        print(f"æ— è®°å¿†ç‰ˆæœ¬é•¿åº¦: {len(simple_response)} å­—ç¬¦")
        print(f"ä¸ªæ€§åŒ–ç¨‹åº¦å¯¹æ¯”: {'æœ‰è®°å¿†ç‰ˆæœ¬æ›´å…·ä¸ªæ€§åŒ–' if len(response) > len(simple_response) else 'å·®å¼‚ä¸æ˜æ˜¾'}")
        
    except Exception as e:
        print(f"âŒ å¯¹æ¯”æµ‹è¯•å¤±è´¥: {str(e)}")
    
    print("\n" + "=" * 60)
    print("ğŸ å¢å¼ºè®°å¿†åŠŸèƒ½æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    asyncio.run(test_enhanced_memory_conversation())
